from zeiss_umbrella.config import FILE_OBSERVER_BASE_PATH, FILE_OBSERVER_RESOURCE_PATH, FILE_OBSERVER_SOURCE_PATH
import sacred
from sacred import Experiment
from sacred.observers.file_storage import FileStorageObserver
import torch.nn as nn
from torch.optim import lr_scheduler
import numpy as np
import torchvision
from zeiss_umbrella.fundus.setting_parser import get_baseline, get_optimizer, get_loss
from zeiss_umbrella.fundus.train import *
from zeiss_umbrella.fundus import data
import pandas as pd
import os

ex = Experiment('incremental balancing')
template = ""
ex.observers.append(FileStorageObserver(FILE_OBSERVER_BASE_PATH,
                                        FILE_OBSERVER_RESOURCE_PATH, FILE_OBSERVER_SOURCE_PATH, template))


# uncomment if you use progress bars
# from sacred.utils import apply_backspaces_and_linefeeds
# ex.captured_out_filter = apply_backspaces_and_linefeeds
# for more info see https://sacred.readthedocs.io/en/latest/collected_information.html#live-information


@ex.config
def my_config():
    """
    preprocessing: dictionary, 'type':'centerCrop','default' , 'cropSize':list, 'size':tuple
    adv_training_config: 'type':'baseline', 'fgsm', 'fgsm_k_image', 'pgd', 'boundary_attack'
                     configuration for fgsm type attack:
                     'epsilon_fgsm': maximum pixel-wise amplitude of perturbation default is 1/255
                     'steps' (bim/pgd): number of iterations
                     'alpha_fgsm': step size of each iteration, default is 2.5 * epsilon_fgsm / steps
                     configuration for decision boundary attack (dba):
                     'epsilon_dba': size of orthogonal move of decision boundary attack, default is 1.
                     'delta_dba': size of move towards target sample, default is 0.1
                     'n_step_max_dba': maximum number of iterations for dba, default is 500
                     'e_step_max_dba': maximum number of iterations for epsilon step, default is 20
                     'd_step_max_dba': maximum number of iterations for delta step, default is 10
                     'diff_tol_dba': stop dba if the mean square error is smaller than this value, default is 10
                     'batch_acc_tol': minimum batch accuracy to trigger boundary attack, default is 0.7
                     'unqualified_sample_ratio_tol_dba': return the adversarial if the ratio of the "bad adv samples" is
                                                         smaller than this threshold
                     global configuration:
                     'weight': Weight of adversarial loss in the total loss, default is 0.3
    loss_setting: 'type': 'crossentropy', 'focal_loss', 'class_balanced', 'inv_freq"
                  configuration for 'focal_loss':
                  'gamma': characterize the rate of drop of well classified data
                  'alpha': weights for each class of type torch.tensor
                  configuration for 'class_balanced':
                  'beta'
    """
    baseline = 'resnet18'
    preprocessing = {'type': 'augmented'}
    gaussian_noise = None
    adv_training_config = {'type': 'baseline'}
    loss_setting = {'type': 'crossentropy'}
    modelname = 'train_' + baseline + '_' + preprocessing['type'] + '_' + adv_training_config["type"] + '_unfreezed' + \
                '_' + loss_setting['type'] + '_' + 'balanced'
    device = 'cuda:2'
    optim_setting = {'optim': 'adam'}
    weight_dir = None
    parallel = False
    balance = 'alternative'
    root_dir = 'data/fundus_preprocessed_512/train/'
    dataset = 'trainLabels.csv'
    train_len = None
    valid_len = None
    valid_rate = 0.3
    num_epoch = 20
    batch_size = 64
    seed = 19660602


@ex.automain
def run(_run: sacred.run.Run, modelname, baseline, preprocessing, device, optim_setting, loss_setting, seed,
        train_len, valid_len, valid_rate, num_epoch, batch_size, adv_training_config, root_dir, dataset,
        weight_dir, parallel, balance, gaussian_noise):
    # run is a special variable, an instance of https://sacred.readthedocs.io/en/latest/apidoc.html#api-run
    # if we had some input data which is required to run this experiment, we could add it here.
    # This is only important if the input data changes a lot/is generated by some other experiment though
    import os
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    f = data.FundusDataset(root_dir=root_dir, csv_name=dataset, transform_dic=preprocessing)

    # Settings
    criterion = get_loss(loss_setting)
    model = get_baseline(baseline, pretrain=True,
                         weights_dir=weight_dir, parallel=parallel)
    model = model.to(device)
    optimizer = get_optimizer(optim_setting, model.parameters())
    print("Training ", modelname)
    for epoch in range(num_epoch):
        ind = epoch % 5
        # print("Let's use", torch.cuda.device_count(), "GPUs!")
        loaders, sizes, train_label_dist, valid_label_dist = data.get_fundus_train(root_dir=root_dir,
                                                                                   original_csv_name=dataset,
                                                                                   transform_dic=preprocessing,
                                                                                   seed=seed,
                                                                                   balance=balance,
                                                                                   k=5,
                                                                                   gaussian_noise=gaussian_noise,
                                                                                   shuffle=True,
                                                                                   batch_size=batch_size,
                                                                                   valid_rate=valid_rate,
                                                                                   train_len=train_len,
                                                                                   valid_len=valid_len, ind=ind)
        model, best_model_weights, optimizer \
            = train_model(model, loaders, sizes, criterion, optimizer, device, scheduler=None, valid=True, ex=ex,
                          seed=seed,
                          fundus_dataset=f, num_epochs=1, adv_training_config=adv_training_config, return_best=True)

    # this will store any produced artifacts like images, trained weights etc.
    # As well as output the metrics
    torch.save(model.state_dict(), modelname)
    torch.save(best_model_weights, modelname + '_best')
    torch.save(optimizer.state_dict(), 'optimizer_state')
    _run.add_artifact(modelname)
    _run.add_artifact(modelname + '_best')
    _run.add_artifact('optimizer_state')
    # remove artifacts once done to not clutter
    import os
    os.remove(modelname)
    os.remove(modelname + '_best')
    os.remove('optimizer_state')
